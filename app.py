# # üõ°Ô∏è Fix for corrupted macOS hidden style files crashing matplotlib
# # This block attempts to fix a specific matplotlib issue on macOS by removing
# # potentially corrupted hidden style files. It might not be necessary on all systems.
# import os
# import glob
# import shutil
# import sys

# # Check if running in Streamlit Cloud or a similar environment where filesystem access might be restricted
# # or if the path doesn't exist.
# try:
#     # Construct path relative to sys.executable, more robust in venvs
#     base_dir = os.path.dirname(sys.executable)
#     # Common venv structure: <venv>/bin/python -> <venv>/lib/pythonX.Y/site-packages
#     # Adjust relative path based on typical venv layout
#     stylelib_path_candidates = [
#         os.path.join(base_dir, "../lib", f"python{sys.version_info.major}.{sys.version_info.minor}", "site-packages", "matplotlib/mpl-data/stylelib"), # Linux/macOS venv
#         os.path.join(base_dir, "Lib", "site-packages", "matplotlib/mpl-data/stylelib") # Windows venv
#     ]
#     stylelib_path = None
#     for candidate in stylelib_path_candidates:
#         if os.path.exists(os.path.normpath(candidate)):
#             stylelib_path = os.path.normpath(candidate)
#             break

#     if stylelib_path and os.path.exists(stylelib_path):
#         removed_files = []
#         for f in glob.glob(os.path.join(stylelib_path, "._*")):
#             try:
#                 os.remove(f)
#                 removed_files.append(os.path.basename(f))
#             except OSError as e:
#                 # Log warning if removal fails, but don't crash the app
#                 print(f"Warning: Could not remove matplotlib style file {f}: {e}")
#         # Optional: Log removal for debugging
#         # if removed_files:
#         #     print(f"Removed potentially corrupted style files: {removed_files}")
#     # else:
#     #     print(f"Matplotlib stylelib path not found or inaccessible among candidates.") # Optional: for debugging

# except Exception as e:
#     print(f"Warning: Failed during matplotlib style cleanup: {e}")
# # ---------------- End of macOS Fix -----------------

# # üîß Standard Library Imports
# import traceback
# from io import StringIO, BytesIO
# import re # For cleaning LLM output

# # üì¶ Third-party Imports
# import streamlit as st
# import pandas as pd
# import numpy as np # <-- ADDED NUMPY IMPORT
# import matplotlib
# matplotlib.use('Agg') # Set backend before importing pyplot
# import matplotlib.pyplot as plt
# import seaborn as sns
# from PIL import Image  # For handling images

# # üß† Local Imports
# from prompt_templates import (
#     get_preprocessing_code,
#     get_flexible_analysis_code,
#     get_eda_summary
# )
# from utils import extract_sample

# # --- Helper Function for Cleaning LLM Code Output ---
# def clean_llm_code_output(code_string):
#     """Removes markdown code fences and leading/trailing whitespace from LLM code output."""
#     if not isinstance(code_string, str):
#         return "" # Return empty string if input is not a string

#     # Remove ```python, ```, etc., from start and end using regex
#     code_string = re.sub(r"^\s*```[a-zA-Z]*\s*", "", code_string)
#     code_string = re.sub(r"\s*```\s*$", "", code_string)
#     code_string = code_string.strip(' \n`\'"')
#     return code_string

# # --- Helper Function for Code Execution ---
# # WARNING: Using exec() can be insecure if the generated code is not trusted.
# def execute_generated_code(code_string, local_vars, is_display_code=False):
#     """
#     Executes the generated Python code string safely within a specific context.
#     Captures and stores ALL matplotlib plots generated for persistent display.

#     Args:
#         code_string (str): The Python code to execute.
#         local_vars (dict): A dictionary containing variables accessible to the code
#                            (e.g., {'df': dataframe}). It will be updated inplace.
#         is_display_code (bool): If True, attempt to display and store matplotlib plots 
#                                 generated by the code.

#     Returns:
#         object: Returns the object assigned to 'df' in local_vars after execution,
#                 typically the modified DataFrame. Returns None if 'df' is not found
#                 or if execution fails.
#     """
#     # Ensure required libraries are in the execution scope
#     global_context = {
#         "pd": pd,
#         "sns": sns,
#         "st": st,
#         "plt": plt,
#         "np": np,
#         **local_vars # Include df and potentially other inputs
#     }

#     # Clear any pre-existing figures from previous Streamlit reruns or code executions
#     plt.close('all')

#     try:
#         # Execute the code. Code operates on the objects in local_vars.
#         exec(code_string, global_context, local_vars)

#         # Capture and store plots if this is analysis code
#         if is_display_code:
#             fig_nums = plt.get_fignums()  # Get IDs of all open figures
            
#             # Reset stored figures if this is the first run of a new analysis
#             if st.session_state.analysis_run == False:
#                 st.session_state.figure_pngs = []
                
#             if fig_nums:
#                 for i in fig_nums:
#                     fig = plt.figure(i)  # Get the specific figure object
                    
#                     # Save figure to a BytesIO buffer for persistent storage
#                     buf = BytesIO()
#                     fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')
#                     buf.seek(0)
                    
#                     # Store the buffer in session state
#                     st.session_state.figure_pngs.append(buf)
                    
#                     # Display the current figure in Streamlit
#                     st.pyplot(fig)
                
#                 plt.close('all')  # Close all figures after displaying them
#             # else:
#             #    st.info("‚ÑπÔ∏è The analysis code ran, but no plots were generated or detected.")

#         # Return the updated 'df' object from the execution context
#         return local_vars.get('df', None)

#     except Exception as e:
#         st.error(f"‚ùå Error executing generated code:\n```python\n{code_string}\n```\n**Error details:**\n```\n{traceback.format_exc()}\n```")
#         plt.close('all')  # Attempt to close figures even if an error occurred
#         return None  # Indicate failure by returning None

# # --- Streamlit App Configuration ---
# st.set_page_config(page_title="AI Data Analyst Assistant", layout="wide")
# st.title("üß† AI-Powered Data Analyst Assistant")

# # --- Initialize Session State ---
# # Use session state to store data and state across reruns
# if 'df_original' not in st.session_state:
#     st.session_state.df_original = None
# if 'df_cleaned' not in st.session_state:
#     st.session_state.df_cleaned = None
# if 'generated_preprocessing_code' not in st.session_state:
#     st.session_state.generated_preprocessing_code = None
# if 'generated_analysis_code' not in st.session_state:
#     st.session_state.generated_analysis_code = None
# if 'analysis_summary' not in st.session_state:
#     st.session_state.analysis_summary = None
# if 'analysis_requested' not in st.session_state:
#     st.session_state.analysis_requested = False
# if 'preprocessing_done' not in st.session_state:
#     st.session_state.preprocessing_done = False
# if 'analysis_run' not in st.session_state:
#     st.session_state.analysis_run = False
# if 'figure_pngs' not in st.session_state:
#     st.session_state.figure_pngs = []

# # --- File Uploader Callback and Widget ---
# def reset_state_on_new_upload():
#     """Reset session state variables when a new file is uploaded via callback."""
#     # Clear all relevant session state keys
#     keys_to_reset = [
#         'df_original', 'df_cleaned', 'generated_preprocessing_code',
#         'generated_analysis_code', 'analysis_summary', 'analysis_requested',
#         'preprocessing_done', 'analysis_run', 'figure_pngs'
#     ]
#     for key in keys_to_reset:
#         if key in st.session_state:
#             del st.session_state[key]
#     # Re-initialize keys to ensure they exist
#     st.session_state.df_original = None
#     st.session_state.df_cleaned = None
#     st.session_state.generated_preprocessing_code = None
#     st.session_state.generated_analysis_code = None
#     st.session_state.analysis_summary = None
#     st.session_state.analysis_requested = False
#     st.session_state.preprocessing_done = False
#     st.session_state.analysis_run = False
#     st.session_state.figure_pngs = []


# uploaded_file = st.file_uploader(
#     "üìÇ Upload a CSV file",
#     type=["csv"],
#     key="file_uploader", # Key allows tracking the widget state
#     on_change=reset_state_on_new_upload # Use the callback
# )

# # --- File Processing Logic ---
# # This block runs only if a file is uploaded and not yet processed into session state
# if uploaded_file is not None and st.session_state.df_original is None:
#     try:
#         bytes_data = uploaded_file.getvalue()
#         try:
#             decoded_content = bytes_data.decode("utf-8")
#         except UnicodeDecodeError:
#             try:
#                 decoded_content = bytes_data.decode("latin1")
#                 st.warning("‚ö†Ô∏è File was not UTF-8 encoded. Read using Latin-1. Check data for potential character issues.")
#             except Exception as decode_err:
#                  st.error(f"‚ùå Failed to decode file with UTF-8 or Latin-1: {decode_err}")
#                  st.stop() # Stop if decoding fails completely

#         df = pd.read_csv(StringIO(decoded_content))
#         st.session_state.df_original = df.copy() # Store a copy in session state
#         st.success("‚úÖ File uploaded successfully.")
#         st.rerun() # Rerun immediately after successful upload to update UI state

#     except pd.errors.ParserError as e:
#         st.error(f"‚ùå Error parsing CSV file: {e}. Please ensure it's a valid CSV.")
#         st.session_state.df_original = None # Ensure state is reset on error
#     except Exception as e:
#         st.error(f"‚ùå An unexpected error occurred while reading the file: {e}")
#         st.session_state.df_original = None


# # --- Main Application Flow (runs if DataFrame is loaded in session state) ---
# if st.session_state.df_original is not None:

#     st.subheader("üìÑ Uploaded Data Preview (First 5 Rows)")
#     st.dataframe(st.session_state.df_original.head())

#     columns, sample = extract_sample(st.session_state.df_original)

#     st.subheader("üìù What would you like to explore or analyze?")
#     user_prompt = st.text_area(
#         "Example: 'Show the distribution of sales per region', 'Compare average age by department', 'Plot price vs area'",
#         key="user_prompt_input", # Assign key for stability if needed elsewhere
#         height=100
#     )

#     if st.button("üöÄ Generate Analysis Plan", key="start_analysis_button"):
#         if user_prompt.strip():
#             st.session_state.analysis_requested = True
#             # Reset downstream states for a new plan
#             st.session_state.preprocessing_done = False
#             st.session_state.analysis_run = False
#             st.session_state.df_cleaned = None
#             st.session_state.generated_analysis_code = None
#             st.session_state.analysis_summary = None
#             st.session_state.figure_pngs = []  # Clear any previous figures

#             # --- Generate Codes and Summary ---
#             with st.spinner("üß† Generating preprocessing code..."):
#                  # Regenerate preprocessing code each time unless it should be static per file
#                  raw_prep_code = get_preprocessing_code(columns, sample)
#                  st.session_state.generated_preprocessing_code = clean_llm_code_output(raw_prep_code)

#             with st.spinner("üß† Generating analysis code..."):
#                 raw_analysis_code = get_flexible_analysis_code(columns, sample, user_prompt)
#                 st.session_state.generated_analysis_code = clean_llm_code_output(raw_analysis_code)

#             with st.spinner("üß† Generating EDA summary..."):
#                  st.session_state.analysis_summary = get_eda_summary(columns, sample, user_prompt)

#             st.rerun() # Rerun to display the newly generated content and update button states
#         else:
#             st.warning("‚ö†Ô∏è Please enter a description of what you want to analyze.")

#     # --- Display Generated Plan and Execute Steps ---
#     if st.session_state.analysis_requested:

#         # --- Display and Apply Preprocessing ---
#         st.subheader("üßπ Step 1: Data Preprocessing Code")
#         if st.session_state.generated_preprocessing_code:
#             st.code(st.session_state.generated_preprocessing_code, language="python")
#             if not st.session_state.preprocessing_done:
#                  if st.button("‚úÖ Apply Preprocessing", key="apply_preprocessing"):
#                      with st.spinner("üßº Applying preprocessing..."):
#                          df_to_clean = st.session_state.df_original.copy()
#                          local_vars = {'df': df_to_clean}
#                          cleaned_df = execute_generated_code(
#                              st.session_state.generated_preprocessing_code,
#                              local_vars,
#                              is_display_code=False
#                          )
#                          if cleaned_df is not None:
#                              st.session_state.df_cleaned = cleaned_df
#                              st.session_state.preprocessing_done = True
#                              st.session_state.analysis_run = False # Analysis needs to be rerun
#                              st.success("‚úÖ Preprocessing applied successfully.")
#                              st.rerun()
#                          else:
#                              st.session_state.preprocessing_done = False
#         else:
#             # Displayed only if analysis_requested is true but code is somehow missing
#             st.warning("‚è≥ Preprocessing code generation failed or is pending.")


#         # --- Display and Run Analysis (only if preprocessing is done) ---
#         if st.session_state.preprocessing_done:
#              # Ensure df_cleaned exists before proceeding
#             if st.session_state.df_cleaned is not None:
#                 st.subheader("üìä Step 2: Data Analysis Code")
#                 if st.session_state.generated_analysis_code:
#                     st.code(st.session_state.generated_analysis_code, language="python")
#                     if not st.session_state.analysis_run:
#                         if st.button("üìà Run Analysis", key="run_analysis"):
#                             with st.spinner("‚öôÔ∏è Running analysis... Please wait..."):
#                                 df_for_analysis = st.session_state.df_cleaned.copy()
#                                 local_vars = {'df': df_for_analysis}
#                                 # Execute analysis code
#                                 execute_generated_code(
#                                     st.session_state.generated_analysis_code,
#                                     local_vars,
#                                     is_display_code=True # Display plots
#                                 )
#                                 st.session_state.analysis_run = True
#                                 st.success("‚úÖ Analysis executed.")
#                                 # Rerun to update UI state (e.g., hide run button)
#                                 st.rerun()
#                 else:
#                     st.warning("‚è≥ Analysis code generation failed or is pending.")

#                 # --- Display Stored Visualizations (if analysis has been run) ---
#                 if st.session_state.analysis_run:
#                     st.subheader("üìä Analysis Results")
#                     if st.session_state.figure_pngs:
#                         for png_buf in st.session_state.figure_pngs:
#                             # Reset buffer position and display the image
#                             png_buf.seek(0)
#                             image = Image.open(png_buf)
#                             st.image(image)
#                     else:
#                         st.info("No visualizations were generated from the analysis.")

#                 # --- Display Results & Summaries (Always show if preprocessing is done) ---
#                 # st.subheader("üí° Step 3: Insights & Data Overview")

#                 # if st.session_state.analysis_summary:
#                 #     st.markdown("### Predicted Insights Summary")
#                 #     st.markdown(st.session_state.analysis_summary)
#                 #     st.divider()

#                 # with st.expander("üîç Glimpse at Cleaned Data & Info", expanded=False): # Start collapsed
#                 #     st.write("**Cleaned Data Sample (First 5 Rows):**")
#                 #     st.dataframe(st.session_state.df_cleaned.head())
#                 #     st.write("**Column Types after Cleaning:**")
#                 #     try:
#                 #         dtypes_df = pd.DataFrame(st.session_state.df_cleaned.dtypes, columns=['DataType'])
#                 #         dtypes_df.index.name = 'Column'
#                 #         st.dataframe(dtypes_df)
#                 #     except Exception as e:
#                 #         st.warning(f"Could not display data types: {e}")

#                 #     st.write("**Summary Statistics (Cleaned Data):**")
#                 #     try:
#                 #         # Generate description, handling potential errors for mixed types
#                 #         description = st.session_state.df_cleaned.describe(include='all')
#                 #         st.dataframe(description)
#                 #     except Exception as desc_err:
#                 #         st.warning(f"Could not generate full summary statistics: {desc_err}. Falling back to numeric.")
#                 #         try:
#                 #             st.dataframe(st.session_state.df_cleaned.describe())
#                 #         except Exception as num_desc_err:
#                 #              st.error(f"Could not generate numeric summary statistics: {num_desc_err}")


#                 # --- Display Results & Summaries (Always show if preprocessing is done) ---
#                 st.subheader("üí° Step 3: Insights & Data Overview")

#                 if st.session_state.analysis_run:
#                     if st.session_state.analysis_summary:
#                         st.markdown("### Analysis Insights")
#                         st.markdown(st.session_state.analysis_summary)
#                         st.divider()
                        
#                     # Add a refresh insights button to regenerate the summary after seeing the actual results
#                     if st.button("üîÑ Refresh Insights Based on Results", key="refresh_insights"):
#                         with st.spinner("üß† Generating updated insights based on results..."):
#                             # Create a more contextual prompt that includes information about the actual analysis results
#                             result_context = "The analysis has produced visualizations showing "
#                             if len(st.session_state.figure_pngs) == 0:
#                                 result_context += "no visual plots, but tabular or statistical results."
#                             elif len(st.session_state.figure_pngs) == 1:
#                                 result_context += "one visualization related to the user's query."
#                             else:
#                                 result_context += f"{len(st.session_state.figure_pngs)} visualizations related to the user's query."
                                
#                             # Add this context to our original prompt
#                             enhanced_prompt = f"{user_prompt}\n\nAdditional context: {result_context}"
                            
#                             # Get refreshed insights
#                             st.session_state.analysis_summary = get_eda_summary(columns, sample, enhanced_prompt)
#                             st.rerun()
#                 else:
#                     if st.session_state.analysis_summary:
#                         st.markdown("### Predicted Insights")
#                         st.info("‚ö†Ô∏è These are preliminary insights. Run the analysis to see actual results and get more accurate insights.")
#                         st.markdown(st.session_state.analysis_summary)
#                         st.divider()

#                 with st.expander("üîç Glimpse at Cleaned Data & Info", expanded=False): # Start collapsed
#                     st.write("**Cleaned Data Sample (First 5 Rows):**")
#                     st.dataframe(st.session_state.df_cleaned.head())
#                     st.write("**Column Types after Cleaning:**")
#                     try:
#                         dtypes_df = pd.DataFrame(st.session_state.df_cleaned.dtypes, columns=['DataType'])
#                         dtypes_df.index.name = 'Column'
#                         st.dataframe(dtypes_df)
#                     except Exception as e:
#                         st.warning(f"Could not display data types: {e}")

#                     st.write("**Summary Statistics (Cleaned Data):**")
#                     try:
#                         # Generate description, handling potential errors for mixed types
#                         description = st.session_state.df_cleaned.describe(include='all')
#                         st.dataframe(description)
#                     except Exception as desc_err:
#                         st.warning(f"Could not generate full summary statistics: {desc_err}. Falling back to numeric.")
#                         try:
#                             st.dataframe(st.session_state.df_cleaned.describe())
#                         except Exception as num_desc_err:
#                                 st.error(f"Could not generate numeric summary statistics: {num_desc_err}")


#             else:
#                  # This case should ideally not happen if preprocessing_done is True, but safety check
#                  st.error("üö® Internal state error: Preprocessing marked as done, but cleaned data is missing.")


#         elif st.session_state.analysis_requested and not st.session_state.preprocessing_done:
#             # Message shown if plan generated, but preprocessing step failed or wasn't run
#             st.info("‚ÑπÔ∏è Apply the preprocessing step first to enable analysis.")

# # --- Footer or Sidebar Info ---
# st.sidebar.markdown("---")
# st.sidebar.header("About")
# st.sidebar.info("This AI assistant helps analyze tabular data. Upload a CSV, describe your analysis goal, and click 'Generate Analysis Plan'. The AI will generate Python code for preprocessing and analysis. Review the code, then click the buttons to execute it step-by-step.")
# st.sidebar.warning("‚ö†Ô∏è **Caution:** The generated code is executed on the server. While efforts are made to ensure safety, review the code before running, especially with sensitive data or in untrusted environments.")

# # Display current date (Optional, consider if needed)
# from datetime import datetime
# st.caption(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")





# --- Styling and Configuration Fix ---
import os
import glob
import shutil
import sys

# Check if running in Streamlit Cloud or a similar environment where filesystem access might be restricted
# or if the path doesn't exist.
try:
    # Construct path relative to sys.executable, more robust in venvs
    base_dir = os.path.dirname(sys.executable)
    # Common venv structure: <venv>/bin/python -> <venv>/lib/pythonX.Y/site-packages
    # Adjust relative path based on typical venv layout
    stylelib_path_candidates = [
        os.path.join(base_dir, "../lib", f"python{sys.version_info.major}.{sys.version_info.minor}", "site-packages", "matplotlib/mpl-data/stylelib"), # Linux/macOS venv
        os.path.join(base_dir, "Lib", "site-packages", "matplotlib/mpl-data/stylelib") # Windows venv
    ]
    stylelib_path = None
    for candidate in stylelib_path_candidates:
        if os.path.exists(os.path.normpath(candidate)):
            stylelib_path = os.path.normpath(candidate)
            break

    if stylelib_path and os.path.exists(stylelib_path):
        removed_files = []
        for f in glob.glob(os.path.join(stylelib_path, "._*")):
            try:
                os.remove(f)
                removed_files.append(os.path.basename(f))
            except OSError as e:
                # Log warning if removal fails, but don't crash the app
                print(f"Warning: Could not remove matplotlib style file {f}: {e}")
except Exception as e:
    print(f"Warning: Failed during matplotlib style cleanup: {e}")

# --- Standard Library Imports ---
import traceback
from io import StringIO, BytesIO
import re
from datetime import datetime

# --- Third-party Imports ---
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image

# --- Local Imports ---
from prompt_templates import (
    get_preprocessing_code,
    get_flexible_analysis_code,
    get_eda_summary
)
from utils import extract_sample

# --- Set Theme and Custom CSS ---
st.set_page_config(
    page_title="Smart Data Analyst",
    layout="wide", 
    initial_sidebar_state="expanded"
)

# Custom CSS for styling
st.markdown("""
<style>
    /* Main content area styling */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    /* Headers styling */
    h1 {
        color: #1E3A8A;
        margin-bottom: 1.5rem;
    }
    h2 {
        color: #1E3A8A;
        opacity: 0.9;
        margin-top: 1.5rem;
    }
    h3 {
        color: #3B82F6;
        margin-top: 1rem;
    }
    
    /* Code block styling */
    .stCodeBlock {
        border-radius: 5px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* Button styling */
    .stButton > button {
        border-radius: 6px;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }
    
    /* Success button */
    .success-btn > button {
        background-color: #10B981;
        color: white;
    }
    
    /* Primary button */
    .primary-btn > button {
        background-color: #3B82F6;
        color: white;
    }
    
    /* Info button */
    .info-btn > button {
        background-color: #6366F1;
        color: white;
    }
    
    /* Card styling */
    .card {
        padding: 1.5rem;
        border-radius: 8px;
        background-color: white;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        margin-bottom: 1rem;
    }
    
    /* Divider styling */
    hr {
        margin: 2rem 0;
        border: none;
        height: 1px;
        background-color: #E5E7EB;
    }
    
    /* Status indicators */
    .status-complete {
        color: #10B981;
        font-weight: 500;
    }
    .status-pending {
        color: #F59E0B;
        font-weight: 500;
    }
    
    /* File uploader styling */
    .uploadedFile {
        border-radius: 4px !important;
    }
    
    /* Expander styling */
    .streamlit-expanderHeader {
        font-weight: 600;
        color: #4B5563;
    }
</style>
""", unsafe_allow_html=True)

# --- Helper Function for Cleaning LLM Code Output ---
def clean_llm_code_output(code_string):
    """Removes markdown code fences and leading/trailing whitespace from LLM code output."""
    if not isinstance(code_string, str):
        return ""

    # Remove ```python, ```, etc., from start and end using regex
    code_string = re.sub(r"^\s*```[a-zA-Z]*\s*", "", code_string)
    code_string = re.sub(r"\s*```\s*$", "", code_string)
    code_string = code_string.strip(' \n`\'"')
    return code_string

# --- Helper Function for Code Execution ---
def execute_generated_code(code_string, local_vars, is_display_code=False):
    """
    Executes the generated Python code string safely within a specific context.
    Captures and stores ALL matplotlib plots generated for persistent display.
    """
    # Ensure required libraries are in the execution scope
    global_context = {
        "pd": pd,
        "sns": sns,
        "st": st,
        "plt": plt,
        "np": np,
        **local_vars
    }

    # Clear any pre-existing figures from previous Streamlit reruns or code executions
    plt.close('all')

    try:
        # Execute the code. Code operates on the objects in local_vars.
        exec(code_string, global_context, local_vars)

        # Capture and store plots if this is analysis code
        if is_display_code:
            fig_nums = plt.get_fignums()  # Get IDs of all open figures
            
            # Reset stored figures if this is the first run of a new analysis
            if st.session_state.analysis_run == False:
                st.session_state.figure_pngs = []
                
            if fig_nums:
                for i in fig_nums:
                    fig = plt.figure(i)  # Get the specific figure object
                    
                    # Save figure to a BytesIO buffer for persistent storage
                    buf = BytesIO()
                    fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')
                    buf.seek(0)
                    
                    # Store the buffer in session state
                    st.session_state.figure_pngs.append(buf)
                    
                    # Always display the figure, even if st.pyplot was commented out in the code
                    st.pyplot(fig)
                
                plt.close('all')  # Close all figures after displaying them
            else:
                st.info("The analysis code ran successfully, but no visualizations were created. Check if the analysis requires plots.")

        # Return the updated 'df' object from the execution context
        return local_vars.get('df', None)

    except Exception as e:
        st.error(f"Error executing generated code: {str(e)}\n\n{traceback.format_exc()}")
        plt.close('all')  # Attempt to close figures even if an error occurred
        return None  # Indicate failure by returning None
    




    
# --- Initialize Session State ---
if 'df_original' not in st.session_state:
    st.session_state.df_original = None
if 'df_cleaned' not in st.session_state:
    st.session_state.df_cleaned = None
if 'generated_preprocessing_code' not in st.session_state:
    st.session_state.generated_preprocessing_code = None
if 'generated_analysis_code' not in st.session_state:
    st.session_state.generated_analysis_code = None
if 'analysis_summary' not in st.session_state:
    st.session_state.analysis_summary = None
if 'analysis_requested' not in st.session_state:
    st.session_state.analysis_requested = False
if 'preprocessing_done' not in st.session_state:
    st.session_state.preprocessing_done = False
if 'analysis_run' not in st.session_state:
    st.session_state.analysis_run = False
if 'figure_pngs' not in st.session_state:
    st.session_state.figure_pngs = []

# --- File Uploader Callback and Widget ---
def reset_state_on_new_upload():
    """Reset session state variables when a new file is uploaded via callback."""
    # Clear all relevant session state keys
    keys_to_reset = [
        'df_original', 'df_cleaned', 'generated_preprocessing_code',
        'generated_analysis_code', 'analysis_summary', 'analysis_requested',
        'preprocessing_done', 'analysis_run', 'figure_pngs'
    ]
    for key in keys_to_reset:
        if key in st.session_state:
            del st.session_state[key]
    # Re-initialize keys to ensure they exist
    st.session_state.df_original = None
    st.session_state.df_cleaned = None
    st.session_state.generated_preprocessing_code = None
    st.session_state.generated_analysis_code = None
    st.session_state.analysis_summary = None
    st.session_state.analysis_requested = False
    st.session_state.preprocessing_done = False
    st.session_state.analysis_run = False
    st.session_state.figure_pngs = []

# --- Sidebar Content ---
with st.sidebar:
    st.title("Smart Data Analyst")
    
    st.markdown("### Upload Data")
    uploaded_file = st.file_uploader(
        "Select a CSV file to analyze",
        type=["csv"],
        key="file_uploader",
        on_change=reset_state_on_new_upload
    )
    
    st.markdown("---")
    st.markdown("### About")
    st.info(
        "This AI assistant helps analyze tabular data. Upload a CSV, describe your analysis goal, and "
        "generate an analysis plan. The AI will create code for preprocessing and analysis that you can "
        "execute step-by-step."
    )
    st.warning(
        "**Note:** The generated code is executed on the server. Review the code before running, "
        "especially with sensitive data."
    )
    
    # Visual indicators for workflow state
    if st.session_state.df_original is not None:
        st.markdown("### Analysis Progress")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**Data**")
            if st.session_state.df_original is not None:
                st.markdown('<p class="status-complete">Loaded</p>', unsafe_allow_html=True)
            else:
                st.markdown('<p class="status-pending">Pending</p>', unsafe_allow_html=True)
        
        with col2:
            st.markdown("**Preprocessing**")
            if st.session_state.preprocessing_done:
                st.markdown('<p class="status-complete">Complete</p>', unsafe_allow_html=True)
            else:
                st.markdown('<p class="status-pending">Pending</p>', unsafe_allow_html=True)
        
        with col3:
            st.markdown("**Analysis**")
            if st.session_state.analysis_run:
                st.markdown('<p class="status-complete">Complete</p>', unsafe_allow_html=True)
            else:
                st.markdown('<p class="status-pending">Pending</p>', unsafe_allow_html=True)

# --- Main Content Area ---
# File Processing Logic
if uploaded_file is not None and st.session_state.df_original is None:
    try:
        bytes_data = uploaded_file.getvalue()
        try:
            decoded_content = bytes_data.decode("utf-8")
        except UnicodeDecodeError:
            try:
                decoded_content = bytes_data.decode("latin1")
                st.warning("File was not UTF-8 encoded. Read using Latin-1. Check data for potential character issues.")
            except Exception as decode_err:
                 st.error(f"Failed to decode file with UTF-8 or Latin-1: {decode_err}")
                 st.stop()

        df = pd.read_csv(StringIO(decoded_content))
        st.session_state.df_original = df.copy()
        st.success("File uploaded successfully.")
        st.rerun()

    except pd.errors.ParserError as e:
        st.error(f"Error parsing CSV file: {e}. Please ensure it's a valid CSV.")
        st.session_state.df_original = None
    except Exception as e:
        st.error(f"An unexpected error occurred while reading the file: {e}")
        st.session_state.df_original = None

# Main Application Flow
if st.session_state.df_original is not None:
    st.title("Interactive Data Analysis")
    
    # Data Preview in a card-like container
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("Data Preview")
    st.dataframe(st.session_state.df_original.head(), use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Extract data sample for prompts
    columns, sample = extract_sample(st.session_state.df_original)
    
    # Analysis Query Section
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("Analysis Query")
    user_prompt = st.text_area(
        "What would you like to explore or analyze?",
        placeholder="Example: 'Show the distribution of sales per region', 'Compare average age by department', or 'Plot price vs area'",
        key="user_prompt_input",
        height=100
    )
    
    # Using custom CSS classes for button styling
    st.markdown('<div class="primary-btn">', unsafe_allow_html=True)
    generate_button = st.button("Generate Analysis Plan", key="start_analysis_button")
    st.markdown('</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)
    
    if generate_button:
        if user_prompt.strip():
            st.session_state.analysis_requested = True
            # Reset downstream states for a new plan
            st.session_state.preprocessing_done = False
            st.session_state.analysis_run = False
            st.session_state.df_cleaned = None
            st.session_state.generated_analysis_code = None
            st.session_state.analysis_summary = None
            st.session_state.figure_pngs = []

            # Generate Codes and Summary
            with st.spinner("Generating preprocessing code..."):
                 raw_prep_code = get_preprocessing_code(columns, sample)
                 st.session_state.generated_preprocessing_code = clean_llm_code_output(raw_prep_code)

            with st.spinner("Generating analysis code..."):
                raw_analysis_code = get_flexible_analysis_code(columns, sample, user_prompt)
                st.session_state.generated_analysis_code = clean_llm_code_output(raw_analysis_code)

            with st.spinner("Generating analysis summary..."):
                 st.session_state.analysis_summary = get_eda_summary(columns, sample, user_prompt)

            st.rerun()
        else:
            st.warning("Please enter a description of what you want to analyze.")

    # Display Generated Plan and Execute Steps
    if st.session_state.analysis_requested:
        # Step 1: Data Preprocessing
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.subheader("Step 1: Data Preprocessing")
        if st.session_state.generated_preprocessing_code:
            st.code(st.session_state.generated_preprocessing_code, language="python")
            if not st.session_state.preprocessing_done:
                st.markdown('<div class="success-btn">', unsafe_allow_html=True)
                if st.button("Apply Preprocessing", key="apply_preprocessing"):
                    with st.spinner("Applying preprocessing..."):
                        df_to_clean = st.session_state.df_original.copy()
                        local_vars = {'df': df_to_clean}
                        cleaned_df = execute_generated_code(
                            st.session_state.generated_preprocessing_code,
                            local_vars,
                            is_display_code=False
                        )
                        if cleaned_df is not None:
                            st.session_state.df_cleaned = cleaned_df
                            st.session_state.preprocessing_done = True
                            st.session_state.analysis_run = False
                            st.success("Preprocessing applied successfully.")
                            st.rerun()
                        else:
                            st.session_state.preprocessing_done = False
                st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.warning("Preprocessing code generation failed or is pending.")
        st.markdown('</div>', unsafe_allow_html=True)

        # Step 2: Data Analysis (only if preprocessing is done)
        if st.session_state.preprocessing_done:
            if st.session_state.df_cleaned is not None:
                st.markdown('<div class="card">', unsafe_allow_html=True)
                st.subheader("Step 2: Data Analysis")
                if st.session_state.generated_analysis_code:
                    st.code(st.session_state.generated_analysis_code, language="python")
                    if not st.session_state.analysis_run:
                        st.markdown('<div class="info-btn">', unsafe_allow_html=True)
                        if st.button("Run Analysis", key="run_analysis"):
                            with st.spinner("Running analysis... Please wait..."):
                                df_for_analysis = st.session_state.df_cleaned.copy()
                                local_vars = {'df': df_for_analysis}
                                # Execute analysis code
                                execute_generated_code(
                                    st.session_state.generated_analysis_code,
                                    local_vars,
                                    is_display_code=True
                                )
                                st.session_state.analysis_run = True
                                st.success("Analysis executed successfully.")
                                st.rerun()
                        st.markdown('</div>', unsafe_allow_html=True)
                else:
                    st.warning("Analysis code generation failed or is pending.")
                st.markdown('</div>', unsafe_allow_html=True)

                # Analysis Results Section
                if st.session_state.analysis_run:
                    st.markdown('<div class="card">', unsafe_allow_html=True)
                    st.subheader("Analysis Results")
                    if st.session_state.figure_pngs:
                        for png_buf in st.session_state.figure_pngs:
                            # Reset buffer position and display the image
                            png_buf.seek(0)
                            image = Image.open(png_buf)
                            st.image(image, use_column_width=True)
                    else:
                        st.info("No visualizations were generated from the analysis.")
                    st.markdown('</div>', unsafe_allow_html=True)

                # Step 3: Insights Section
                st.markdown('<div class="card">', unsafe_allow_html=True)
                st.subheader("Step 3: Insights & Data Overview")

                if st.session_state.analysis_run:
                    if st.session_state.analysis_summary:
                        st.markdown("#### Analysis Insights")
                        st.markdown(st.session_state.analysis_summary)
                        st.markdown("---")
                        
                    # Refresh insights button
                    if st.button("Refresh Insights Based on Results", key="refresh_insights"):
                        with st.spinner("Generating updated insights based on results..."):
                            # Create a more contextual prompt
                            result_context = "The analysis has produced visualizations showing "
                            if len(st.session_state.figure_pngs) == 0:
                                result_context += "no visual plots, but tabular or statistical results."
                            elif len(st.session_state.figure_pngs) == 1:
                                result_context += "one visualization related to the user's query."
                            else:
                                result_context += f"{len(st.session_state.figure_pngs)} visualizations related to the user's query."
                                
                            # Add this context to original prompt
                            enhanced_prompt = f"{user_prompt}\n\nAdditional context: {result_context}"
                            
                            # Get refreshed insights
                            st.session_state.analysis_summary = get_eda_summary(columns, sample, enhanced_prompt)
                            st.rerun()
                else:
                    if st.session_state.analysis_summary:
                        st.markdown("#### Predicted Insights")
                        st.info("These are preliminary insights. Run the analysis to see actual results and get more accurate insights.")
                        st.markdown(st.session_state.analysis_summary)
                        st.markdown("---")

                with st.expander("View Cleaned Data & Statistics"):
                    st.markdown("#### Cleaned Data Sample")
                    st.dataframe(st.session_state.df_cleaned.head(), use_container_width=True)
                    
                    st.markdown("#### Column Types")
                    try:
                        dtypes_df = pd.DataFrame(st.session_state.df_cleaned.dtypes, columns=['DataType'])
                        dtypes_df.index.name = 'Column'
                        st.dataframe(dtypes_df, use_container_width=True)
                    except Exception as e:
                        st.warning(f"Could not display data types: {e}")

                    st.markdown("#### Summary Statistics")
                    try:
                        # Generate description, handling potential errors for mixed types
                        description = st.session_state.df_cleaned.describe(include='all')
                        st.dataframe(description, use_container_width=True)
                    except Exception as desc_err:
                        st.warning(f"Could not generate full summary statistics: {desc_err}. Falling back to numeric.")
                        try:
                            st.dataframe(st.session_state.df_cleaned.describe(), use_container_width=True)
                        except Exception as num_desc_err:
                            st.error(f"Could not generate numeric summary statistics: {num_desc_err}")
                st.markdown('</div>', unsafe_allow_html=True)

            else:
                st.error("Internal state error: Preprocessing marked as done, but cleaned data is missing.")

        elif st.session_state.analysis_requested and not st.session_state.preprocessing_done:
            st.info("Apply the preprocessing step first to enable analysis.")

# Footer with timestamp
st.caption(f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")